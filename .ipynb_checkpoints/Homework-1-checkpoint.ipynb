{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Reading data and regression\n",
    "## Due September 5th\n",
    "\n",
    "In class we've been working on developing the tools for linear regression.  In this homework, we'll use those tools to show that one of the original 'big data' problems can be solved quite credibly with ordinary least squares.  Note that this exercise is primarily intended to do two things: 1) provide you with some practice gathering data, and 2) evaluate your ability to reason somewhat abstractly about models.  With respect to the second point, it is in your grade's interest to provide complete and well-reasoned answers to narrative questions posed.  A correct answer can be awarded very few points if its reasoning is absent or unclear, and an incorrect answer can be awarded full points if it is well argued.   \n",
    "\n",
    "Please turn in your work via github classroom.\n",
    "\n",
    "## The big one\n",
    "If you've ever lived in an area prone to seismic activity, you know that people are always a little apprehensive about *the big one*, that giant earthquake (Magnitude greater than 7) that is going to break the pots and collapse the overpasses.  However, the big one rarely happens... until it does.  What happens more frequently is smaller earthquakes.  And even more frequently than that, even smaller earthquakes.  In fact, it's long been understood that earthquake frequency has an inverse relationship with magnitude.  Here, we're going to quantify that relationship for the west coast of the US.  \n",
    "\n",
    "## Data wrangling\n",
    "The first thing that we'll need to do is to aquire a dataset that can help us say something about earthquake frequency.  Fortunately, the United States Geologic Survey keeps such a database.  \n",
    "\n",
    "First, navigate to https://earthquake.usgs.gov/earthquakes/search/.  This is the USGS' central repository for earthquake data.  We'll be interested in data from the last twenty years.  Enter the appropriate date.  Next, we're interested in data from the west coast of the lower 48.  Use the Custom Geographic Region button on the right side of the page, followed by the Draw Rectangle on the Map button.  Draw a rectangle around the west coast, from the Canadian to Mexican border.  Next, open the Output Options tab and select .csv (comma separated values, a plain text format).  Finally, under Limit Results, enter 19999 (the site will throw an error if you make this value bigger).  This series of commands will deliver the ~20k most recent earthquakes of all sizes to occur in this region of the world.  It may take a moment for their server to pull your query together. Download the file.\n",
    "\n",
    "Next, import the data into ipython.  This is easily done with [Pandas' read_csv function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           time   latitude   longitude   depth   mag magType  \\\n",
      "0      2019-09-03T08:23:33.250Z  36.199000 -117.885000   2.540  2.59      ml   \n",
      "1      2019-09-03T03:41:29.230Z  35.701668 -117.587830   5.340  3.47      mw   \n",
      "2      2019-09-03T03:28:37.320Z  35.631000 -117.434333   2.970  2.67      ml   \n",
      "3      2019-09-03T02:32:14.860Z  35.671001 -117.521332   9.470  3.20      ml   \n",
      "4      2019-09-03T02:29:20.280Z  35.669167 -117.524333  10.020  2.79      ml   \n",
      "...                         ...        ...         ...     ...   ...     ...   \n",
      "19994  2005-01-11T02:47:34.350Z  35.227500 -118.570667   4.578  2.84      ml   \n",
      "19995  2005-01-10T12:13:12.750Z  38.012000 -118.711333   5.082  3.18      ml   \n",
      "19996  2005-01-09T18:35:54.400Z  36.896167 -121.627167   6.983  2.52      md   \n",
      "19997  2005-01-09T10:18:05.940Z  46.197167 -122.186000  -1.471  2.80      md   \n",
      "19998  2005-01-09T00:19:34.310Z  37.312000 -122.125500   4.102  2.54      md   \n",
      "\n",
      "        nst   gap     dmin   rms  ...                   updated  \\\n",
      "0      34.0  61.0  0.08483  0.21  ...  2019-09-03T08:34:40.240Z   \n",
      "1      63.0  56.0  0.11410  0.18  ...  2019-09-03T12:38:30.662Z   \n",
      "2      38.0  56.0  0.03513  0.14  ...  2019-09-03T11:31:11.930Z   \n",
      "3      56.0  62.0  0.09711  0.16  ...  2019-09-03T02:54:40.030Z   \n",
      "4      40.0  37.0  0.05951  0.15  ...  2019-09-03T02:40:23.250Z   \n",
      "...     ...   ...      ...   ...  ...                       ...   \n",
      "19994  62.0  30.0  0.09676  0.23  ...  2016-03-07T23:36:36.152Z   \n",
      "19995  47.0  73.0  0.06937  0.08  ...  2018-04-24T20:44:18.984Z   \n",
      "19996  72.0  45.0  0.03063  0.08  ...  2017-01-10T04:41:54.100Z   \n",
      "19997  15.0  60.0      NaN  0.08  ...  2016-07-22T20:52:51.380Z   \n",
      "19998  53.0  41.0  0.02342  0.11  ...  2017-01-10T04:39:17.400Z   \n",
      "\n",
      "                                    place        type horizontalError  \\\n",
      "0                  14km SE of Olancha, CA  earthquake           0.320   \n",
      "1               12km NE of Ridgecrest, CA  earthquake           0.160   \n",
      "2            15km S of Searles Valley, CA  earthquake           0.180   \n",
      "3              15km ENE of Ridgecrest, CA  earthquake           0.180   \n",
      "4              15km ENE of Ridgecrest, CA  earthquake           0.190   \n",
      "...                                   ...         ...             ...   \n",
      "19994            15km NW of Tehachapi, CA  earthquake           0.250   \n",
      "19995                  Central California  earthquake           0.200   \n",
      "19996                  Central California  earthquake           0.140   \n",
      "19997   Mount St. Helens area, Washington  earthquake           0.255   \n",
      "19998  San Francisco Bay area, California  earthquake           0.130   \n",
      "\n",
      "      depthError  magError  magNst     status  locationSource magSource  \n",
      "0           1.83     0.177    24.0  automatic              ci        ci  \n",
      "1           0.86       NaN     6.0   reviewed              ci        ci  \n",
      "2           0.29     0.208    25.0  automatic              ci        ci  \n",
      "3           0.44     0.228    17.0  automatic              ci        ci  \n",
      "4           0.38     0.134    25.0  automatic              ci        ci  \n",
      "...          ...       ...     ...        ...             ...       ...  \n",
      "19994       0.86     0.219    63.0   reviewed              ci        ci  \n",
      "19995       0.65       NaN     5.0   reviewed              nc        nc  \n",
      "19996       0.27     0.120    75.0   reviewed              nc        nc  \n",
      "19997       0.19     0.040     7.0   reviewed              uw        uw  \n",
      "19998       0.22     0.120    60.0   reviewed              nc        nc  \n",
      "\n",
      "[19999 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use pandas to import the earthquake data file here\n",
    "from pprint import pprint\n",
    "import pandas\n",
    "\n",
    "earthquake_filename = \"earthquakes.csv\"\n",
    "earthquakes = pandas.read_csv(earthquake_filename)\n",
    "pprint(earthquakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrogate the Pandas dataframe for the available fields using its built in method 'keys'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time',\n",
      " 'latitude',\n",
      " 'longitude',\n",
      " 'depth',\n",
      " 'mag',\n",
      " 'magType',\n",
      " 'nst',\n",
      " 'gap',\n",
      " 'dmin',\n",
      " 'rms',\n",
      " 'net',\n",
      " 'id',\n",
      " 'updated',\n",
      " 'place',\n",
      " 'type',\n",
      " 'horizontalError',\n",
      " 'depthError',\n",
      " 'magError',\n",
      " 'magNst',\n",
      " 'status',\n",
      " 'locationSource',\n",
      " 'magSource']\n"
     ]
    }
   ],
   "source": [
    "earthquake_keys = list(earthquakes.keys())\n",
    "pprint(earthquake_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're primarily interested in determining the relationship between relative frequency and magnitude.  Extract the magnitude variable from the pandas data frame using the 'mag' key.  \n",
    "\n",
    "Next, you'll need to determine the number of earthquakes that occured in the data as a function of magnitude.  This is easily done by deciding on a set of bins, and then counting the number of items in each bin.  This is also known as a [histogram](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html), and is easily computed using either numpy or matplotlib.  You'll want to use a fairly large number of bins, say 50 (equally spaced).  *Note that the histogram function provided by either of the above libraries returns total counts rather than relative frequencies: you'll need to compute relative frequencies by dividing the returned counts by the total number of earthquakes in the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2.59\n",
      "1        3.47\n",
      "2        2.67\n",
      "3        3.20\n",
      "4        2.79\n",
      "         ... \n",
      "19994    2.84\n",
      "19995    3.18\n",
      "19996    2.52\n",
      "19997    2.80\n",
      "19998    2.54\n",
      "Name: mag, Length: 19999, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "magnitude = earthquakes[\"mag\"]\n",
    "pprint(magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(20 pts) Make a plot with bin centroids on the $x$-axis and relative frequency on the $y$-axis.  Based on your results, please provide a few sentences describing whether the model $y = w_0 + w_1 x$ is a good fit to the data, if $x$ represents earthquake magnitude and $y$ represents relative frequency.**\n",
    "\n",
    "!Answers go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, a physical model that gives the predicted relative frequency of earthquakes of different magnitudes can be derived from physics, and is given by a so-called *power-law*\n",
    "$$\n",
    "y = ax^b\n",
    "$$\n",
    "**(20pts) If you wanted to directly fit this power-law model to these data, would you be able to use the linear regression code that we've already developed to do so?  If so, how?  If not, why not?**\n",
    "\n",
    "!Answers go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, it is not possible to use linear regression to fit this model directly.  However, it can be done by using a clever transformation of the data.  **(20pts) Plot the base-10 logarithm of the event counts.  Now does a linear model seem like a good fit?  If the power law is a good fit to the untransformed data, why does it make sense that a linear model should fit the log-transformed data (HINT: take the logarithm of both sides of the power law)**\n",
    "\n",
    "!Answers go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, **(40pts) use one of the methods that you developed for linear regression in class to fit a line to the log-transformed counts.  What is the slope of that line?  Is the model a good fit for all sizes of earthquake?**\n",
    "\n",
    "!Answers go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
